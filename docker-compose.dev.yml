version: '3.8'

services:
  # Backend API (Development)
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: ai-persona-backend-dev
    ports:
      - "8000:8000"
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - OPENAI_MODEL=gpt-4
      - OPENAI_EMBEDDING_MODEL=text-embedding-ada-002
      - APP_NAME=AI Persona
      - APP_VERSION=1.0.0
      - DEBUG=True
      - HOST=0.0.0.0
      - PORT=8000
      - DATABASE_URL=sqlite:///./ai_persona.db
      - REDIS_URL=redis://redis:6379
      - CHROMA_PERSIST_DIRECTORY=/app/data/chroma_db
      - SECRET_KEY=${SECRET_KEY:-dev-secret-key}
      - ACCESS_TOKEN_EXPIRE_MINUTES=30
      - CORS_ORIGINS=["http://localhost:3000", "http://localhost:80"]
      - VOICE_MODEL=alloy
      - VOICE_SPEED=1.0
      - VOICE_PITCH=1.0
      - RATE_LIMIT_REQUESTS=1000
      - RATE_LIMIT_WINDOW=3600
    volumes:
      - ./data:/app/data
      - ./backend:/app
    depends_on:
      - redis
    restart: unless-stopped
    command: ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000", "--reload"]

  # Redis for caching
  redis:
    image: redis:7-alpine
    container_name: ai-persona-redis-dev
    ports:
      - "6379:6379"
    volumes:
      - redis_data_dev:/data
    restart: unless-stopped

volumes:
  redis_data_dev:
    driver: local

networks:
  default:
    name: ai-persona-dev-network
